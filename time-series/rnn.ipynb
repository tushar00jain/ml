{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .rendered_html code {\n",
       "            padding: 2px 4px;\n",
       "            color: #c7254e;\n",
       "            background-color: #f9f2f4;\n",
       "            border-radius: 4px;\n",
       "        } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import IPython.display as ipyd \n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code {\n",
    "            padding: 2px 4px;\n",
    "            color: #c7254e;\n",
    "            background-color: #f9f2f4;\n",
    "            border-radius: 4px;\n",
    "        } </style>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# number of time to loop over the data over and over again\n",
    "num_epochs = 10\n",
    "\n",
    "state_size = 4\n",
    "\n",
    "# one hot output (dimensions of the ouput vector)\n",
    "num_classes = 2\n",
    "\n",
    "# total length of the data\n",
    "total_series_length = 50000\n",
    "\n",
    "# how much to shift the input to the right to get the output\n",
    "echo_step = 3\n",
    "\n",
    "# number of rows for the data\n",
    "batch_size = 5\n",
    "# window size for gradient descent\n",
    "truncated_backprop_length = 15\n",
    "# total number of batches\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    # input data\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    # shift the data to the the right and fill the new entries with 0\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    # reshape to matrix\n",
    "    x = x.reshape((batch_size, -1))\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# holds input values for one batch\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "# holds output values for one batch\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "# state vectors for all the batches\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is W\n",
    "# since x_t is only one dimensional, dim(U) is 4 x 1, so we can just include one more column in W that\n",
    "# will represent U\n",
    "W = tf.Variable(np.random.rand(state_size+1, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((1,state_size)), dtype=tf.float32)\n",
    "\n",
    "# this is V\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes), dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# multiple steps will be trained simultaneously\n",
    "# get column vectors (dimension batch sizes) - window size number of vectors\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "current_state = init_state\n",
    "states_series = []\n",
    "for current_input in inputs_series:\n",
    "    # make column vector (dimension batch size)\n",
    "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
    "    # make input and state of the whole batch as one matrix to ease computation\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state], 1)\n",
    "\n",
    "    # next state for all the batches computation all at once\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)\n",
    "    # add next state to the states array\n",
    "    states_series.append(next_state)\n",
    "    # update the current state\n",
    "    current_state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# errors are backpropogated only through the specified window that we are currently working on\n",
    "\n",
    "# get predicted ouputs for all the batches - all the timesteps\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series]\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compute losses\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Loss 0.951066\n",
      "Step 100 Loss 0.450755\n",
      "Step 200 Loss 0.243598\n",
      "Step 300 Loss 0.00649469\n",
      "Step 400 Loss 0.00387137\n",
      "Step 500 Loss 0.00302281\n",
      "Step 600 Loss 0.00265746\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.212604\n",
      "Step 100 Loss 0.00150475\n",
      "Step 200 Loss 0.0013337\n",
      "Step 300 Loss 0.00112596\n",
      "Step 400 Loss 0.000966698\n",
      "Step 500 Loss 0.000778024\n",
      "Step 600 Loss 0.000761148\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.347741\n",
      "Step 100 Loss 0.00178258\n",
      "Step 200 Loss 0.000953126\n",
      "Step 300 Loss 0.000862559\n",
      "Step 400 Loss 0.000733374\n",
      "Step 500 Loss 0.00068691\n",
      "Step 600 Loss 0.000598636\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.261991\n",
      "Step 100 Loss 0.000641246\n",
      "Step 200 Loss 0.000524248\n",
      "Step 300 Loss 0.000453691\n",
      "Step 400 Loss 0.000433275\n",
      "Step 500 Loss 0.000443277\n",
      "Step 600 Loss 0.000391661\n",
      "New data, epoch 4\n",
      "Step 0 Loss 0.215276\n",
      "Step 100 Loss 0.000375752\n",
      "Step 200 Loss 0.000341665\n",
      "Step 300 Loss 0.000356488\n",
      "Step 400 Loss 0.00037756\n",
      "Step 500 Loss 0.000273282\n",
      "Step 600 Loss 0.000327478\n",
      "New data, epoch 5\n",
      "Step 0 Loss 0.285965\n",
      "Step 100 Loss 0.000334382\n",
      "Step 200 Loss 0.000305765\n",
      "Step 300 Loss 0.000281667\n",
      "Step 400 Loss 0.000267457\n",
      "Step 500 Loss 0.000310021\n",
      "Step 600 Loss 0.000250686\n",
      "New data, epoch 6\n",
      "Step 0 Loss 0.27207\n",
      "Step 100 Loss 0.000307323\n",
      "Step 200 Loss 0.000283488\n",
      "Step 300 Loss 0.000285487\n",
      "Step 400 Loss 0.000260606\n",
      "Step 500 Loss 0.00024026\n",
      "Step 600 Loss 0.000239968\n",
      "New data, epoch 7\n",
      "Step 0 Loss 0.264512\n",
      "Step 100 Loss 0.000302459\n",
      "Step 200 Loss 0.000231262\n",
      "Step 300 Loss 0.000218416\n",
      "Step 400 Loss 0.000200404\n",
      "Step 500 Loss 0.000209616\n",
      "Step 600 Loss 0.000200186\n",
      "New data, epoch 8\n",
      "Step 0 Loss 0.280299\n",
      "Step 100 Loss 0.000197447\n",
      "Step 200 Loss 0.000191007\n",
      "Step 300 Loss 0.000191861\n",
      "Step 400 Loss 0.000194224\n",
      "Step 500 Loss 0.000203745\n",
      "Step 600 Loss 0.000175242\n",
      "New data, epoch 9\n",
      "Step 0 Loss 0.204838\n",
      "Step 100 Loss 0.000224527\n",
      "Step 200 Loss 0.000191252\n",
      "Step 300 Loss 0.000147763\n",
      "Step 400 Loss 0.000156117\n",
      "Step 500 Loss 0.000164959\n",
      "Step 600 Loss 0.00018723\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY,\n",
    "                    init_state:_current_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
